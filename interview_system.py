#!/usr/bin/env python3
"""
é¢è¯•é¢˜ç›®AIåˆ†æ + é£ä¹¦æ¨é€ä¸€ä½“åŒ–ç³»ç»Ÿ
é›†æˆAIåˆ†æã€é£ä¹¦APIæ¨é€äºä¸€ä½“çš„å®Œæ•´è§£å†³æ–¹æ¡ˆ
"""

import os
import json
import time
import uuid
import requests
from datetime import datetime
from dotenv import load_dotenv
from zhipuai import ZhipuAI

load_dotenv()

class InterviewAnalysisSystem:
    """é¢è¯•é¢˜ç›®AIåˆ†æ + é£ä¹¦æ¨é€ä¸€ä½“åŒ–ç³»ç»Ÿ"""

    def __init__(self):
        # é£ä¹¦é…ç½®
        self.app_id = os.getenv("INTERVIEW_APP_ID")
        self.app_secret = os.getenv("INTERVIEW_APP_SECRET")
        self.app_token = os.getenv("INTERVIEW_BITABLE_APP_TOKEN")
        self.table_id = os.getenv("INTERVIEW_TABLE_ID")
        self.token = None
        self.token_expire_time = 0

        # AIåˆ†æé…ç½®
        self.api_key = os.getenv("ZHIPUAI_API_KEY")
        self.base_url = os.getenv("ZHIPUAI_BASE_URL", "https://open.bigmodel.cn/api/paas/v4")
        self.model = os.getenv("ZHIPUAI_MODEL", "glm-4-flash-250414")

        # åˆå§‹åŒ–AIå®¢æˆ·ç«¯
        if not self.api_key:
            print("âš ï¸ æœªè®¾ç½® ZHIPUAI_API_KEY")
            self.client = None
        else:
            self.client = ZhipuAI(api_key=self.api_key)

    # ==================== é£ä¹¦APIç›¸å…³æ–¹æ³• ====================

    def get_tenant_token(self):
        """è·å–å¹¶ç¼“å­˜ Tenant Access Token"""
        if self.token and time.time() < self.token_expire_time:
            return self.token

        url = "https://open.feishu.cn/open-apis/auth/v3/tenant_access_token/internal"
        payload = {"app_id": self.app_id, "app_secret": self.app_secret}
        resp = requests.post(url, json=payload)

        if resp.status_code == 200:
            data = resp.json()
            if data.get("code") == 0:
                self.token = data.get("tenant_access_token")
                self.token_expire_time = time.time() + data.get("expire", 7200) - 60
                return self.token
            else:
                print(f"âŒ è·å– Token å¤±è´¥: {data.get('msg')}")
                return None
        else:
            print(f"âŒ è¯·æ±‚ Token å¤±è´¥: {resp.text}")
            return None

    def get_table_fields(self):
        """è·å–è¡¨æ ¼å­—æ®µä¿¡æ¯ï¼Œç”¨äºå­—æ®µæ˜ å°„"""
        token = self.get_tenant_token()
        if not token:
            return None

        url = f"https://open.feishu.cn/open-apis/bitable/v1/apps/{self.app_token}/tables/{self.table_id}/fields"
        headers = {
            "Authorization": f"Bearer {token}",
            "Content-Type": "application/json"
        }

        try:
            resp = requests.get(url, headers=headers)
            if resp.status_code == 200:
                data = resp.json()
                if data.get("code") == 0:
                    fields = data.get("data", {}).get("items", [])
                    field_map = {}
                    for field in fields:
                        # property å¯èƒ½ä¸º nullï¼Œè¿™é‡Œç»Ÿä¸€å…œåº•æˆ {}
                        prop = field.get("property") or {}
                        raw_options = prop.get("options", []) or []
                        # å°†å¤šé€‰/å•é€‰å­—æ®µçš„é€‰é¡¹æ„é€ æˆ name -> id çš„æ˜ å°„ï¼Œä¾¿äºåç»­å†™å…¥æ—¶ä½¿ç”¨é€‰é¡¹ID
                        options_by_name = {}
                        for opt in raw_options:
                            name = opt.get("name")
                            opt_id = opt.get("id")
                            if name:
                                options_by_name[name] = opt_id

                        field_map[field["field_name"]] = {
                            "id": field["field_id"],
                            "type": field["type"],
                            "options": options_by_name
                        }
                        print(f"ğŸ” å­—æ®µ: {field['field_name']} -> {field['field_id']} ({field['type']})")
                    return field_map
            return None
        except Exception as e:
            print(f"âŒ è·å–å­—æ®µä¿¡æ¯å¤±è´¥: {e}")
            return None

    def _add_record(self, record_data):
        """æ·»åŠ è®°å½•åˆ°é£ä¹¦è¡¨æ ¼"""
        token = self.get_tenant_token()
        if not token:
            return False

        url = f"https://open.feishu.cn/open-apis/bitable/v1/apps/{self.app_token}/tables/{self.table_id}/records"
        headers = {
            "Authorization": f"Bearer {token}",
            "Content-Type": "application/json"
        }

        params = {
            "client_token": str(uuid.uuid4())
        }

        try:
            print(f"ğŸ” å‘é€çš„æ•°æ®ç»“æ„: {json.dumps(record_data, ensure_ascii=False, indent=2)[:1000]}...")
            resp = requests.post(url, headers=headers, params=params, json=record_data)

            if resp.status_code == 200:
                data = resp.json()
                if data.get("code") == 0:
                    record_id = data.get("data", {}).get("record", {}).get("record_id")
                    print(f"âœ… é¢è¯•è®°å½•æ·»åŠ æˆåŠŸï¼")
                    print(f"ğŸ“ è®°å½•ID: {record_id}")
                    return True
                else:
                    print(f"âŒ æ·»åŠ è®°å½•å¤±è´¥: {data.get('msg')}")
                    print(f"é”™è¯¯è¯¦æƒ…: {json.dumps(data, ensure_ascii=False, indent=2)}")
                    return False
            else:
                print(f"âŒ è¯·æ±‚å¤±è´¥: {resp.text}")
                return False
        except Exception as e:
            print(f"âŒ æ·»åŠ è®°å½•æ—¶å‡ºé”™: {e}")
            return False

    # ==================== AIåˆ†æç›¸å…³æ–¹æ³• ====================

    def analyze_interview_question(self, question_text, topic=""):
        """åˆ†æé¢è¯•é¢˜ç›®ï¼Œç”Ÿæˆæ·±åº¦è§£æ"""
        if not self.client:
            return self._get_empty_structure()

        # æˆªæ–­è¿‡é•¿æ–‡æœ¬
        question_text = question_text[:8000]

        # æ„å»ºé¢è¯•åˆ†æçš„ä¸“é—¨ prompt
        prompt = f"""
ä½ æ˜¯ä¸€ä½èµ„æ·±çš„äº’è”ç½‘äº§å“æˆ˜ç•¥ä¸“å®¶å’Œé¢è¯•è¾…å¯¼è€å¸ˆã€‚è¯·æ·±åº¦åˆ†æä»¥ä¸‹é¢è¯•é¢˜ã€‚

é¢˜ç›®ï¼š{topic}
è¯¦ç»†æè¿°ï¼š{question_text}

è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¿”å›åˆ†æç»“æœï¼Œä¸è¦åŒ…å«ä»»ä½•å…¶ä»–æ–‡å­—æˆ–markdownæ ‡è®°ï¼š

{{
    "åŸºç¡€ä¿¡æ¯": {{
        "é¢˜ç›®è¯é¢˜": "æå–é¢˜ç›®çš„æ ¸å¿ƒè¯é¢˜",
        "æ¶‰åŠäº§å“/å…¬å¸": ["åˆ—å‡ºç›¸å…³çš„å…¬å¸æˆ–äº§å“"],
        "ä¸šåŠ¡ç±»å‹": ["ç”µå•†", "ç¤¾äº¤", "å·¥å…·", "O2O", "å†…å®¹", "é‡‘è", "æ¸¸æˆ", "æ•™è‚²", "åŒ»ç–—", "å‡ºè¡Œ", "å…¶ä»–"],
        "éš¾åº¦è¯„çº§": "â­â­â­" // ä»â­åˆ°â­â­â­â­â­
    }},
    "æ·±åº¦è§£æ": {{
        "è¡¨å±‚ç°è±¡": "æè¿°çœ‹åˆ°çš„å®¢è§‚äº‹å®ï¼Œç”¨1-2å¥è¯æ¦‚æ‹¬",
        "æˆ˜ç•¥æ„å›¾": ["æµé‡è·å–ï¼ˆæ‹‰æ–°/ä¿ƒæ´»ï¼‰", "é˜²å¾¡/æŠ¤åŸæ²³", "å˜ç°/è¥æ”¶", "ç”Ÿæ€é—­ç¯", "å“ç‰Œå»ºè®¾", "æŠ€æœ¯å¸ƒå±€", "ç”¨æˆ·ç•™å­˜", "å…¶ä»–"],
        "æ ¸å¿ƒå•†ä¸šé€»è¾‘": "ç”¨ä¸€å¥è¯æ¦‚æ‹¬æœ¬è´¨ï¼Œä½“ç°å•†ä¸šæ´å¯Ÿ",
        "å…³é”®æ”¯æ’‘/èµ„æº": "åˆ†æåšæˆè¿™ä»¶äº‹éœ€è¦çš„å…³é”®èµ„æºå’Œèƒ½åŠ›",
        "æ‰¹åˆ¤æ€§æ€è€ƒ/é£é™©ç‚¹": "æŒ‡å‡ºæ½œåœ¨çš„æŒ‘æˆ˜ã€é£é™©æˆ–åç›´è§‰çš„è§‚ç‚¹"
    }},
    "æ–¹æ³•è®º": {{
        "æ¶‰åŠæ€ç»´æ¨¡å‹": ["é«˜é¢‘æ‰“ä½é¢‘", "ç½‘ç»œæ•ˆåº”", "è¾¹é™…æˆæœ¬", "ä¾›éœ€å…³ç³»", "å›´é­æ•‘èµµ", "å•ä½ç»æµæ¨¡å‹(UE)", "ç”¨æˆ·ä½“éªŒäº”è¦ç´ ", "æ¼æ–—æ¨¡å‹", "é£è½®æ•ˆåº”", "é•¿å°¾ç†è®º", "ç ´çª—æ•ˆåº”", "é©¬å¤ªæ•ˆåº”", "ç°åº¦åˆ›æ–°", "ç¬¬ä¸€æ€§åŸç†", "SWOTåˆ†æ", "æ³¢å£«é¡¿çŸ©é˜µ", "æ³¢ç‰¹äº”åŠ›", "å…¶ä»–"]
    }},
    "é¢è¯•å¤‡æˆ˜": {{
        "è€ƒå¯Ÿèƒ½åŠ›é¡¹": ["å•†ä¸šæ•æ„Ÿåº¦", "æˆ˜ç•¥è§†é‡", "ç”¨æˆ·åŒç†å¿ƒ", "æ•°æ®åˆ†æèƒ½åŠ›", "èµ„æºæ•´åˆèƒ½åŠ›", "äº§å“æ€ç»´", "è¿è¥æ€ç»´", "æŠ€æœ¯ç†è§£", "å¸‚åœºæ´å¯Ÿ", "æ²Ÿé€šè¡¨è¾¾", "é€»è¾‘æ€ç»´", "åˆ›æ–°æ€ç»´", "å…¶ä»–"],
        "å›ç­”é‡‘å¥/å…³é”®è¯": "æä¾›3-5ä¸ªé¢è¯•æ—¶å¿…é¡»è¯´å‡ºçš„å¾—åˆ†å…³é”®è¯æˆ–é‡‘å¥",
        "å›ç­”æ¡†æ¶": "æä¾›ä¸€ä¸ªæ¸…æ™°çš„å›ç­”æ¡†æ¶ï¼ŒåŒ…å«å¼€åœºã€åˆ†æã€æ€»ç»“",
        "å¸¸è§è¯¯åŒº": "æŒ‡å‡ºç°è±¡å›ç­”æ—¶å®¹æ˜“çŠ¯çš„é”™è¯¯"
    }},
    "AIåˆ†ææ€»ç»“": {{
        "æ ¸å¿ƒæ´å¯Ÿ": "ç”¨2-3å¥è¯æ€»ç»“è¿™é“é¢˜çš„æ ¸å¿ƒä»·å€¼",
        "å­¦ä¹ å»ºè®®": "å»ºè®®å¦‚ä½•è¿›ä¸€æ­¥æŒæ¡è¿™ç±»é¢˜ç›®",
        "æ‰©å±•æ€è€ƒ": "æå‡º1-2ä¸ªç›¸å…³çš„å»¶ä¼¸é—®é¢˜"
    }}
}}

åˆ†æè¦æ±‚ï¼š
1. æ·±åº¦æŒ–æ˜é¢˜ç›®èƒŒåçš„å•†ä¸šé€»è¾‘å’Œæˆ˜ç•¥æ€è€ƒ
2. ä½“ç°ä¸“ä¸šçš„å•†ä¸šåˆ†ææ¡†æ¶å’Œæ€ç»´æ¨¡å‹
3. æä¾›å®ç”¨çš„é¢è¯•å»ºè®®å’Œå›ç­”æŠ€å·§
4. åˆ†æè¦å®¢è§‚ã€æ·±å…¥ï¼Œæœ‰æ´å¯ŸåŠ›
5. ç¡®ä¿JSONæ ¼å¼æ­£ç¡®ï¼Œå¯ä»¥ç›´æ¥è§£æ
"""

        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„äº’è”ç½‘äº§å“æˆ˜ç•¥ä¸“å®¶ï¼Œæ“…é•¿æ·±åº¦åˆ†æå•†ä¸šæ¡ˆä¾‹å’Œé¢è¯•é¢˜ç›®ã€‚"},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.3,
                max_tokens=4000
            )

            if response and response.choices:
                content = response.choices[0].message.content.strip()

                # æ¸…ç†å¯èƒ½çš„markdownæ ‡è®°
                content = content.replace('```json', '').replace('```', '').strip()

                try:
                    # æ¸…ç†å¯èƒ½çš„æ ¼å¼é—®é¢˜
                    content = content.replace(',\\n    }', '\\n    }')  # ç§»é™¤æœ€åä¸€ä¸ªé€—å·
                    result = json.loads(content)
                    print("âœ… é¢è¯•é¢˜ç›®åˆ†æå®Œæˆ")
                    return result
                except json.JSONDecodeError as e:
                    print(f"âŒ JSONè§£æå¤±è´¥: {e}")
                    # å°è¯•æå–åŸå§‹å†…å®¹ä¸­çš„æœ‰ç”¨ä¿¡æ¯
                    try:
                        # ç®€å•çš„ä¿®å¤ç­–ç•¥
                        content = content.replace(',\\n    }', '\\n    }').replace(',\\n}', '\\n}')
                        result = json.loads(content)
                        print("âœ… ä¿®å¤åè§£ææˆåŠŸ")
                        return result
                    except:
                        print(f"åŸå§‹å†…å®¹: {content[:1000]}...")
                        return self._get_fallback_structure(content)

            return self._get_empty_structure()

        except Exception as e:
            print(f"âŒ åˆ†æé¢è¯•é¢˜ç›®æ—¶å‡ºé”™: {e}")
            return self._get_empty_structure()

    def _get_empty_structure(self):
        """è¿”å›ç©ºçš„åˆ†æç»“æ„"""
        return {
            "åŸºç¡€ä¿¡æ¯": {
                "é¢˜ç›®è¯é¢˜": "",
                "æ¶‰åŠäº§å“/å…¬å¸": [],
                "ä¸šåŠ¡ç±»å‹": [],
                "éš¾åº¦è¯„çº§": "â­â­â­"
            },
            "æ·±åº¦è§£æ": {
                "è¡¨å±‚ç°è±¡": "",
                "æˆ˜ç•¥æ„å›¾": [],
                "æ ¸å¿ƒå•†ä¸šé€»è¾‘": "",
                "å…³é”®æ”¯æ’‘/èµ„æº": "",
                "æ‰¹åˆ¤æ€§æ€è€ƒ/é£é™©ç‚¹": ""
            },
            "æ–¹æ³•è®º": {
                "æ¶‰åŠæ€ç»´æ¨¡å‹": []
            },
            "é¢è¯•å¤‡æˆ˜": {
                "è€ƒå¯Ÿèƒ½åŠ›é¡¹": [],
                "å›ç­”é‡‘å¥/å…³é”®è¯": "",
                "å›ç­”æ¡†æ¶": "",
                "å¸¸è§è¯¯åŒº": ""
            },
            "AIåˆ†ææ€»ç»“": {
                "æ ¸å¿ƒæ´å¯Ÿ": "",
                "å­¦ä¹ å»ºè®®": "",
                "æ‰©å±•æ€è€ƒ": ""
            }
        }

    def _get_fallback_structure(self, raw_content):
        """JSONè§£æå¤±è´¥æ—¶çš„å¤‡ç”¨ç»“æ„"""
        base_structure = self._get_empty_structure()
        base_structure["AIåˆ†ææ€»ç»“"]["æ ¸å¿ƒæ´å¯Ÿ"] = f"åŸå§‹AIå›ç­”ï¼š{raw_content[:500]}..."
        return base_structure

    # ==================== ä¸»è¦é›†æˆæ–¹æ³• ====================

    def add_interview_record(self, question_text, topic=""):
        """åˆ†æé¢è¯•é¢˜ç›®å¹¶æ·»åŠ åˆ°é£ä¹¦è¡¨æ ¼ï¼ˆå®Œæ•´æµç¨‹ï¼‰"""
        print("ğŸš€ å¼€å§‹åˆ†æé¢è¯•é¢˜ç›®...")

        # ä½¿ç”¨AIåˆ†æé¢è¯•é¢˜ç›®
        analysis_result = self.analyze_interview_question(question_text, topic)

        if not analysis_result or analysis_result.get("åŸºç¡€ä¿¡æ¯", {}).get("é¢˜ç›®è¯é¢˜") == "":
            print("âŒ AIåˆ†æå¤±è´¥ï¼Œæ— æ³•æ·»åŠ è®°å½•")
            return False

        print("âœ… AIåˆ†æå®Œæˆï¼Œå‡†å¤‡å†™å…¥é£ä¹¦è¡¨æ ¼...")

        # è·å–å­—æ®µæ˜ å°„
        field_map = self.get_table_fields()
        if not field_map:
            print("âŒ è·å–å­—æ®µæ˜ å°„å¤±è´¥")
            return False

        # æ„å»ºè®°å½•æ•°æ®
        record_data = {
            "fields": {}
        }

        # åŸºç¡€ä¿¡æ¯åŒº
        if "é¢˜ç›®/è¯é¢˜" in field_map:
            # æ–‡æœ¬å­—æ®µç›´æ¥ä¼ å­—ç¬¦ä¸²
            record_data["fields"]["é¢˜ç›®/è¯é¢˜"] = analysis_result["åŸºç¡€ä¿¡æ¯"].get("é¢˜ç›®è¯é¢˜", topic)

        if "æ¶‰åŠäº§å“/å…¬å¸" in field_map:
            companies = analysis_result["åŸºç¡€ä¿¡æ¯"].get("æ¶‰åŠäº§å“/å…¬å¸", [])
            if companies:
                # å¤šé€‰å­—æ®µä½¿ç”¨å­—ç¬¦ä¸²åˆ—è¡¨
                record_data["fields"]["æ¶‰åŠäº§å“/å…¬å¸"] = [str(c) for c in companies]

        if "ä¸šåŠ¡ç±»å‹" in field_map:
            business_types = analysis_result["åŸºç¡€ä¿¡æ¯"].get("ä¸šåŠ¡ç±»å‹", [])
            if business_types:
                # å•é€‰å­—æ®µä½¿ç”¨å­—ç¬¦ä¸²
                record_data["fields"]["ä¸šåŠ¡ç±»å‹"] = str(business_types[0])

        if "åˆ›å»ºæ—¶é—´" in field_map:
            # Use milliseconds timestamp for Feishu API
            record_data["fields"]["åˆ›å»ºæ—¶é—´"] = int(datetime.now().timestamp() * 1000)

        # æ·±åº¦è§£æåŒº
        if "è¡¨å±‚ç°è±¡ (Phenomenon)" in field_map:
            phenomenon = analysis_result["æ·±åº¦è§£æ"].get("è¡¨å±‚ç°è±¡", "")
            if phenomenon:
                record_data["fields"]["è¡¨å±‚ç°è±¡ (Phenomenon)"] = phenomenon

        if "æˆ˜ç•¥æ„å›¾ (Strategic Intent)" in field_map:
            intents = analysis_result["æ·±åº¦è§£æ"].get("æˆ˜ç•¥æ„å›¾", [])
            if intents:
                record_data["fields"]["æˆ˜ç•¥æ„å›¾ (Strategic Intent)"] = [str(i) for i in intents]

        if "æ ¸å¿ƒå•†ä¸šé€»è¾‘ (Core Logic)" in field_map:
            logic = analysis_result["æ·±åº¦è§£æ"].get("æ ¸å¿ƒå•†ä¸šé€»è¾‘", "")
            if logic:
                record_data["fields"]["æ ¸å¿ƒå•†ä¸šé€»è¾‘ (Core Logic)"] = logic

        if "å…³é”®æ”¯æ’‘/èµ„æº (Key Resources)" in field_map:
            resources = analysis_result["æ·±åº¦è§£æ"].get("å…³é”®æ”¯æ’‘/èµ„æº", "")
            if resources:
                record_data["fields"]["å…³é”®æ”¯æ’‘/èµ„æº (Key Resources)"] = resources

        if "æ‰¹åˆ¤æ€§æ€è€ƒ/é£é™©ç‚¹ (Critical Thinking)" in field_map:
            risks = analysis_result["æ·±åº¦è§£æ"].get("æ‰¹åˆ¤æ€§æ€è€ƒ/é£é™©ç‚¹", "")
            if risks:
                record_data["fields"]["æ‰¹åˆ¤æ€§æ€è€ƒ/é£é™©ç‚¹ (Critical Thinking)"] = risks

        # æ–¹æ³•è®ºæ²‰æ·€åŒº
        if "æ¶‰åŠæ€ç»´æ¨¡å‹" in field_map:
            models = analysis_result["æ–¹æ³•è®º"].get("æ¶‰åŠæ€ç»´æ¨¡å‹", [])
            if models:
                record_data["fields"]["æ¶‰åŠæ€ç»´æ¨¡å‹"] = [str(m) for m in models]

        # é¢è¯•å¤‡æˆ˜åŒº
        if "è€ƒå¯Ÿèƒ½åŠ›é¡¹" in field_map:
            abilities = analysis_result["é¢è¯•å¤‡æˆ˜"].get("è€ƒå¯Ÿèƒ½åŠ›é¡¹", [])
            if abilities:
                record_data["fields"]["è€ƒå¯Ÿèƒ½åŠ›é¡¹"] = [str(a) for a in abilities]

        if "å›ç­”é‡‘å¥/å…³é”®è¯" in field_map:
            # é¢è¯•Agentä¸­è¯¥å­—æ®µæ˜¯å­—ç¬¦ä¸²ï¼Œè¿™é‡Œç»Ÿä¸€è½¬æˆå­—ç¬¦ä¸²å†™å…¥
            keywords = analysis_result["é¢è¯•å¤‡æˆ˜"].get("å›ç­”é‡‘å¥/å…³é”®è¯", "")
            if isinstance(keywords, list):
                keywords_text = ", ".join(keywords)
            else:
                keywords_text = str(keywords)
            if keywords_text:
                record_data["fields"]["å›ç­”é‡‘å¥/å…³é”®è¯"] = keywords_text

        if "AIåˆ†æç»“æœ" in field_map:
            ai_summary = f"""ğŸ“‹ æ ¸å¿ƒæ´å¯Ÿï¼š{analysis_result["AIåˆ†ææ€»ç»“"].get("æ ¸å¿ƒæ´å¯Ÿ", "")}

ğŸ“š å­¦ä¹ å»ºè®®ï¼š{analysis_result["AIåˆ†ææ€»ç»“"].get("å­¦ä¹ å»ºè®®", "")}

ğŸ¤” æ‰©å±•æ€è€ƒï¼š{analysis_result["AIåˆ†ææ€»ç»“"].get("æ‰©å±•æ€è€ƒ", "")}

ğŸ’¡ å›ç­”æ¡†æ¶ï¼š{analysis_result["é¢è¯•å¤‡æˆ˜"].get("å›ç­”æ¡†æ¶", "")}

âš ï¸ å¸¸è§è¯¯åŒºï¼š{analysis_result["é¢è¯•å¤‡æˆ˜"].get("å¸¸è§è¯¯åŒº", "")}"""
            # å¤šè¡Œæ–‡æœ¬å­—æ®µä¹Ÿç›´æ¥ä¼ å­—ç¬¦ä¸²
            record_data["fields"]["AIåˆ†æç»“æœ"] = ai_summary

        if "éš¾åº¦è¯„çº§" in field_map:
            difficulty = analysis_result["åŸºç¡€ä¿¡æ¯"].get("éš¾åº¦è¯„çº§", "â­â­â­")
            # å•é€‰å­—æ®µä½¿ç”¨å­—ç¬¦ä¸²
            record_data["fields"]["éš¾åº¦è¯„çº§"] = str(difficulty)

        if "æŒæ¡ç¨‹åº¦" in field_map:
            record_data["fields"]["æŒæ¡ç¨‹åº¦"] = "ğŸŸ¡ äº†è§£"  # é»˜è®¤çŠ¶æ€

        return self._add_record(record_data)

    def test_connection(self):
        """æµ‹è¯•è¿æ¥"""
        print("ğŸ” æµ‹è¯•é¢è¯•è®°å½•é£ä¹¦è¿æ¥...")

        # æµ‹è¯•è·å–token
        token = self.get_tenant_token()
        if token:
            print("âœ… Tokenè·å–æˆåŠŸ")

            # æµ‹è¯•è·å–å­—æ®µ
            field_map = self.get_table_fields()
            if field_map:
                print(f"âœ… å­—æ®µè·å–æˆåŠŸï¼Œå…±{len(field_map)}ä¸ªå­—æ®µ")
                return True
            else:
                print("âŒ å­—æ®µè·å–å¤±è´¥")
                return False
        else:
            print("âŒ Tokenè·å–å¤±è´¥")
            return False


def main():
    """ä¸»å‡½æ•° - é¢è¯•é¢˜ç›®åˆ†æå¹¶æ¨é€åˆ°é£ä¹¦"""
    system = InterviewAnalysisSystem()

    print("=== é¢è¯•é¢˜ç›®AIåˆ†æ + é£ä¹¦æ¨é€ç³»ç»Ÿ ===")
    print("ğŸ¤– AIæ¨¡å‹ï¼šæ™ºè°±AI GLM-Flash")
    print("ğŸ“Š ç›®æ ‡ï¼šé£ä¹¦å¤šç»´è¡¨æ ¼")
    print("="*50)

    # æµ‹è¯•è¿æ¥
    if not system.test_connection():
        print("âŒ è¿æ¥æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥é…ç½®")
        return

    # æµ‹è¯•æ·»åŠ é¢è¯•è®°å½•
    print("\n=== æ·»åŠ æµ‹è¯•é¢è¯•è®°å½• ===")

    test_question = """
    äº¬ä¸œä¸ºä»€ä¹ˆå…¥å±€å¤–å–ï¼Ÿ

    æœ€è¿‘çœ‹åˆ°äº¬ä¸œå¼€å§‹åœ¨å¤šä¸ªåŸå¸‚æ‹›å‹Ÿéª‘æ‰‹ï¼Œå¹¶ä¸”åœ¨äº¬ä¸œAPPå†…ä¸Šçº¿äº†å¤–å–å…¥å£ï¼Œæ­£å¼åˆ‡å…¥é¤é¥®é…é€å¸‚åœºã€‚
    è¿™çœ‹èµ·æ¥æ˜¯è¦å’Œç¾å›¢ã€é¥¿äº†ä¹ˆæ­£é¢ç«äº‰ã€‚

    ä»äº¬ä¸œçš„è§’åº¦æ¥çœ‹ï¼š
    - å·²ç»æœ‰äº†è¾¾è¾¾å¿«é€çš„ç‰©æµç½‘ç»œ
    - æœ‰å¼ºå¤§çš„ä¾›åº”é“¾å’Œä»“å‚¨èƒ½åŠ›
    - Plusä¼šå‘˜ç”¨æˆ·åŸºç¡€åºå¤§
    - ä½†å¤–å–å¸‚åœºç«äº‰éå¸¸æ¿€çƒˆ

    æƒ³åˆ†æä¸€ä¸‹äº¬ä¸œè¿™ä¸ªæˆ˜ç•¥é€‰æ‹©çš„é€»è¾‘ã€‚
    """

    topic = "äº¬ä¸œä¸ºä»€ä¹ˆå…¥å±€å¤–å–ï¼Ÿ"

    success = system.add_interview_record(test_question, topic)

    if success:
        print("\nğŸ‰ é¢è¯•è®°å½•æ·»åŠ æˆåŠŸï¼")
        print("ğŸ’¡ ä½ å¯ä»¥åˆ°é£ä¹¦è¡¨æ ¼ä¸­æŸ¥çœ‹å®Œæ•´çš„AIåˆ†æç»“æœ")
    else:
        print("\nâŒ é¢è¯•è®°å½•æ·»åŠ å¤±è´¥")


if __name__ == "__main__":
    main()